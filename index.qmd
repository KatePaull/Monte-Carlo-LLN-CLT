---
title: "Monte Carlo Simulation - Law of Large Numbers and Central Limit Theorem"
---

```{r setup, include=FALSE}

#purpose of chunk: suppress warnings for ggplots - R generates a warning about bin sizes that is irrelevant. ggplots contain four separate frequency polygons where one bin size is not going to be appropriate for all polygons.

knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

## Motivation

The purpose of this Monte Carlo simulation is to visualize the law of large numbers and the central limit theorem using a sequence of increasing sample sizes.

This project was inspired by an econometrics lecture in Stata by Professor Jesse Anttila-Hughes at the University of San Francisco. The purpose of this code is to perform a similar simulation in R.

## Law of Large Numbers

A theorem that says that the average from (a large number of independent and identically distributed) random samples converges in probability to the population average (Wooldridge 2020).

## Central Limit Theorem

A key result from probability theory which implies that the sum of independent random variables, or even weakly dependent random variables, when standardized by its standard deviation, has a distribution that tends to standard normal as the sample size grows (Wooldridge 2020).

## Vizualization of CLT and LLN

I will perform the following steps below to visualize these two concepts:

1.  Generate a sample of data, run a linear regression, and estimate the parameter of interest, which will be known as "Beta 1 Hat."

2.  Repeat step 1 for 1,000 iterations and save each estimate of Beta 1 Hat. These are stored in order to visualize the distribution of these estimates.

3.  Perform steps 1 and 2 across four sample sizes (10, 100, 1,000, and 10,000) so we can see how the distribution becomes increasingly normally distributed and how it converges to the population mean (which is equal to four) as the sample size increases without bound.

Code is provided below for further reference if desired.

```{r}
#| code-fold: true

suppressMessages(
  library(tidyverse)
)

set.seed(1)

sample_size = c(10, 100, 1000, 10000) #create dif sample sizes to show how parameter estimates converge as sample grows w/o bound
sample_size_name = c("reg_10", "reg_100", "reg_1,000", "reg_10,000") #need non-numeric vals for column names

#function purpose: generate dataset for regression, then run 1,000 regressions on each sample size listed above
regression_function <- function(sample_size_name, sample_size) {
  sample_size_name <- as.data.frame(t(sapply(
    1:1000, function(x) tibble( #1,000 regs for each sample to show distribution of parameter estimates at each sample size
      x = 4 * rnorm(sample_size),
      u = 3 * rnorm(sample_size),
      y = 17 + 4*x + u) %>% 
      lm(y ~ x, .)
  ))) %>% 
    unnest_wider(coefficients) %>% #convert data from list format to numeric
    select(x) #keep only parameter estimate columns
}

reg_results <- as.data.frame(mapply(regression_function, sample_size_name, sample_size)) #apply function to name and sample size vectors

reg_results <- reg_results %>% 
  pivot_longer( #tidy data so every column is a variable and every row is an observation
  cols = ends_with(".x"),
  names_to = "sample_size_name",
    values_to = "beta_1_hat"
  ) %>% 
  mutate(sample_size_name = as.factor(str_remove_all(sample_size_name, "[reg_.x]"))) %>%
  arrange(sample_size_name)

freqpoly_distributions <- reg_results %>% 
  ggplot(aes(beta_1_hat, color = sample_size_name)) +
  geom_freqpoly() +
  scale_x_continuous(breaks = seq(from = 1, to = 7, by = 1)) +
  theme_bw() +
  labs(
    x = "Beta 1 Hat",
    y = "Count",
    title = "Central Limit Theorem (CLT) & the Law of Large Numbers (LLN)",
    subtitle = "\n- The CLT tells us that as the sample size grows without bound,\n  our sample mean will be normally distributed (bell shaped)\n\n- The LLN tells us that as the sample size grows without bound,\n  our sample mean converges to the true population mean (equal to 4)\n"
  ) +
  guides(color = guide_legend(title = "Sample Size"))

faceted_freqpoly_distributions <- reg_results %>% 
  ggplot(aes(beta_1_hat, color = sample_size_name)) +
  geom_freqpoly() +
  facet_wrap(~sample_size_name) +
  scale_x_continuous(breaks = seq(from = 1, to = 7, by = 1)) +
  theme_bw() +
    labs(
    x = "Beta 1 Hat",
    y = "Count",
    title = "Central Limit Theorem (CLT) & the Law of Large Numbers (LLN)"
  ) +
  guides(color = guide_legend(title = "Sample Size"))
```

::: panel-tabset
## All Distributions

```{r}
#| echo: false

freqpoly_distributions
```

## Individual Distributions by Sample Size

```{r}
#| echo: false

faceted_freqpoly_distributions
```
:::

## References

::: {#refs}
Wooldridge, J.M.(2020). Introductory Econometrics: A Modern Approach. Brazil: Cengage Learning.
:::
